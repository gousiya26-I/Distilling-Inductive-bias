{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mmcv-full"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RK3Fp0kOqwoB",
        "outputId": "c69e556f-c403-4d7a-a28c-e61a821eb8ba"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mmcv-full\n",
            "  Downloading mmcv-full-1.7.1.tar.gz (605 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m605.4/605.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting addict (from mmcv-full)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (23.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv-full) (6.0.1)\n",
            "Collecting yapf (from mmcv-full)\n",
            "  Downloading yapf-0.40.1-py3-none-any.whl (250 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata>=6.6.0 (from yapf->mmcv-full)\n",
            "  Downloading importlib_metadata-6.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full) (3.10.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv-full) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv-full) (3.16.2)\n",
            "Building wheels for collected packages: mmcv-full\n",
            "  Building wheel for mmcv-full (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mmcv-full: filename=mmcv_full-1.7.1-cp310-cp310-linux_x86_64.whl size=30370720 sha256=b33d22e0394877860b56d54eacce0f8386abc08b5eef0e196232425e48a8429f\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/9a/65/470be18e21a8f2d085a024f0731508273543de0b5f79d9ddd4\n",
            "Successfully built mmcv-full\n",
            "Installing collected packages: addict, importlib-metadata, yapf, mmcv-full\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib-metadata 4.6.4\n",
            "    Uninstalling importlib-metadata-4.6.4:\n",
            "      Successfully uninstalled importlib-metadata-4.6.4\n",
            "Successfully installed addict-2.4.0 importlib-metadata-6.8.0 mmcv-full-1.7.1 yapf-0.40.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Involution CUDA"
      ],
      "metadata": {
        "id": "Cir9b8W4rIT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# set the random seed for reproducibility\n",
        "torch.manual_seed(43)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nMV99LWKriNo",
        "outputId": "95cf0bdf-2aad-47ac-c082-a39eb637b431"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d00f032c2f0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from mmcv.cnn import ConvModule\n",
        "\n",
        "\n",
        "class involution(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 channels,\n",
        "                 kernel_size,\n",
        "                 stride):\n",
        "        super(involution, self).__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.channels = channels\n",
        "        reduction_ratio = 4\n",
        "        self.group_channels = 16\n",
        "        self.groups = self.channels // self.group_channels\n",
        "        self.conv1 = ConvModule(\n",
        "            in_channels=channels,\n",
        "            out_channels=channels // reduction_ratio,\n",
        "            kernel_size=1,\n",
        "            conv_cfg=None,\n",
        "            norm_cfg=dict(type='BN'),\n",
        "            act_cfg=dict(type='ReLU'))\n",
        "        self.conv2 = ConvModule(\n",
        "            in_channels=channels // reduction_ratio,\n",
        "            out_channels=kernel_size**2 * self.groups,\n",
        "            kernel_size=1,\n",
        "            stride=1,\n",
        "            conv_cfg=None,\n",
        "            norm_cfg=None,\n",
        "            act_cfg=None)\n",
        "        if stride > 1:\n",
        "            self.avgpool = nn.AvgPool2d(stride, stride)\n",
        "        self.unfold = nn.Unfold(kernel_size, 1, (kernel_size-1)//2, stride)\n",
        "\n",
        "    def forward(self, x):\n",
        "        weight = self.conv2(self.conv1(x if self.stride == 1 else self.avgpool(x)))\n",
        "        b, c, h, w = weight.shape\n",
        "        weight = weight.view(b, self.groups, self.kernel_size**2, h, w).unsqueeze(2)\n",
        "        out = self.unfold(x).view(b, self.groups, self.group_channels, self.kernel_size**2, h, w)\n",
        "        out = (weight * out).sum(dim=3).view(b, self.channels, h, w)\n",
        "        return out"
      ],
      "metadata": {
        "id": "dPFdXSOre-n0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "531b0f23-08ae-4a20-ad6d-cd2582b93e56"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.autograd import Function\n",
        "import torch\n",
        "from torch.nn.modules.utils import _pair\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from mmcv.cnn import ConvModule\n",
        "\n",
        "\n",
        "from collections import namedtuple\n",
        "import cupy\n",
        "from string import Template\n",
        "\n",
        "\n",
        "Stream = namedtuple('Stream', ['ptr'])\n",
        "\n",
        "\n",
        "def Dtype(t):\n",
        "    if isinstance(t, torch.cuda.FloatTensor):\n",
        "        return 'float'\n",
        "    elif isinstance(t, torch.cuda.DoubleTensor):\n",
        "        return 'double'\n",
        "\n",
        "\n",
        "@cupy._util.memoize(for_each_device=True)\n",
        "def load_kernel(kernel_name, code, **kwargs):\n",
        "    code = Template(code).substitute(**kwargs)\n",
        "    kernel_code = cupy.cuda.compile_with_cache(code)\n",
        "    return kernel_code.get_function(kernel_name)\n",
        "\n",
        "\n",
        "CUDA_NUM_THREADS = 1024\n",
        "\n",
        "kernel_loop = '''\n",
        "#define CUDA_KERNEL_LOOP(i, n)                        \\\n",
        "  for (int i = blockIdx.x * blockDim.x + threadIdx.x; \\\n",
        "      i < (n);                                       \\\n",
        "      i += blockDim.x * gridDim.x)\n",
        "'''\n",
        "\n",
        "\n",
        "def GET_BLOCKS(N):\n",
        "    return (N + CUDA_NUM_THREADS - 1) // CUDA_NUM_THREADS\n",
        "\n",
        "\n",
        "_involution_kernel = kernel_loop + '''\n",
        "extern \"C\"\n",
        "__global__ void involution_forward_kernel(\n",
        "const ${Dtype}* bottom_data, const ${Dtype}* weight_data, ${Dtype}* top_data) {\n",
        "  CUDA_KERNEL_LOOP(index, ${nthreads}) {\n",
        "    const int n = index / ${channels} / ${top_height} / ${top_width};\n",
        "    const int c = (index / ${top_height} / ${top_width}) % ${channels};\n",
        "    const int h = (index / ${top_width}) % ${top_height};\n",
        "    const int w = index % ${top_width};\n",
        "    const int g = c / (${channels} / ${groups});\n",
        "    ${Dtype} value = 0;\n",
        "    #pragma unroll\n",
        "    for (int kh = 0; kh < ${kernel_h}; ++kh) {\n",
        "      #pragma unroll\n",
        "      for (int kw = 0; kw < ${kernel_w}; ++kw) {\n",
        "        const int h_in = -${pad_h} + h * ${stride_h} + kh * ${dilation_h};\n",
        "        const int w_in = -${pad_w} + w * ${stride_w} + kw * ${dilation_w};\n",
        "        if ((h_in >= 0) && (h_in < ${bottom_height})\n",
        "          && (w_in >= 0) && (w_in < ${bottom_width})) {\n",
        "          const int offset = ((n * ${channels} + c) * ${bottom_height} + h_in)\n",
        "            * ${bottom_width} + w_in;\n",
        "          const int offset_weight = ((((n * ${groups} + g) * ${kernel_h} + kh) * ${kernel_w} + kw) * ${top_height} + h)\n",
        "            * ${top_width} + w;\n",
        "          value += weight_data[offset_weight] * bottom_data[offset];\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    top_data[index] = value;\n",
        "  }\n",
        "}\n",
        "'''\n",
        "\n",
        "\n",
        "_involution_kernel_backward_grad_input = kernel_loop + '''\n",
        "extern \"C\"\n",
        "__global__ void involution_backward_grad_input_kernel(\n",
        "    const ${Dtype}* const top_diff, const ${Dtype}* const weight_data, ${Dtype}* const bottom_diff) {\n",
        "  CUDA_KERNEL_LOOP(index, ${nthreads}) {\n",
        "    const int n = index / ${channels} / ${bottom_height} / ${bottom_width};\n",
        "    const int c = (index / ${bottom_height} / ${bottom_width}) % ${channels};\n",
        "    const int h = (index / ${bottom_width}) % ${bottom_height};\n",
        "    const int w = index % ${bottom_width};\n",
        "    const int g = c / (${channels} / ${groups});\n",
        "    ${Dtype} value = 0;\n",
        "    #pragma unroll\n",
        "    for (int kh = 0; kh < ${kernel_h}; ++kh) {\n",
        "      #pragma unroll\n",
        "      for (int kw = 0; kw < ${kernel_w}; ++kw) {\n",
        "        const int h_out_s = h + ${pad_h} - kh * ${dilation_h};\n",
        "        const int w_out_s = w + ${pad_w} - kw * ${dilation_w};\n",
        "        if (((h_out_s % ${stride_h}) == 0) && ((w_out_s % ${stride_w}) == 0)) {\n",
        "          const int h_out = h_out_s / ${stride_h};\n",
        "          const int w_out = w_out_s / ${stride_w};\n",
        "          if ((h_out >= 0) && (h_out < ${top_height})\n",
        "                && (w_out >= 0) && (w_out < ${top_width})) {\n",
        "            const int offset = ((n * ${channels} + c) * ${top_height} + h_out)\n",
        "                  * ${top_width} + w_out;\n",
        "            const int offset_weight = ((((n * ${groups} + g) * ${kernel_h} + kh) * ${kernel_w} + kw) * ${top_height} + h_out)\n",
        "                  * ${top_width} + w_out;\n",
        "            value += weight_data[offset_weight] * top_diff[offset];\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    bottom_diff[index] = value;\n",
        "  }\n",
        "}\n",
        "'''\n",
        "\n",
        "\n",
        "_involution_kernel_backward_grad_weight = kernel_loop + '''\n",
        "extern \"C\"\n",
        "__global__ void involution_backward_grad_weight_kernel(\n",
        "    const ${Dtype}* const top_diff, const ${Dtype}* const bottom_data, ${Dtype}* const buffer_data) {\n",
        "  CUDA_KERNEL_LOOP(index, ${nthreads}) {\n",
        "    const int h = (index / ${top_width}) % ${top_height};\n",
        "    const int w = index % ${top_width};\n",
        "    const int kh = (index / ${kernel_w} / ${top_height} / ${top_width})\n",
        "          % ${kernel_h};\n",
        "    const int kw = (index / ${top_height} / ${top_width}) % ${kernel_w};\n",
        "    const int h_in = -${pad_h} + h * ${stride_h} + kh * ${dilation_h};\n",
        "    const int w_in = -${pad_w} + w * ${stride_w} + kw * ${dilation_w};\n",
        "    if ((h_in >= 0) && (h_in < ${bottom_height})\n",
        "          && (w_in >= 0) && (w_in < ${bottom_width})) {\n",
        "      const int g = (index / ${kernel_h} / ${kernel_w} / ${top_height} / ${top_width}) % ${groups};\n",
        "      const int n = (index / ${groups} / ${kernel_h} / ${kernel_w} / ${top_height} / ${top_width}) % ${num};\n",
        "      ${Dtype} value = 0;\n",
        "      #pragma unroll\n",
        "      for (int c = g * (${channels} / ${groups}); c < (g + 1) * (${channels} / ${groups}); ++c) {\n",
        "        const int top_offset = ((n * ${channels} + c) * ${top_height} + h)\n",
        "              * ${top_width} + w;\n",
        "        const int bottom_offset = ((n * ${channels} + c) * ${bottom_height} + h_in)\n",
        "              * ${bottom_width} + w_in;\n",
        "        value += top_diff[top_offset] * bottom_data[bottom_offset];\n",
        "      }\n",
        "      buffer_data[index] = value;\n",
        "    } else {\n",
        "      buffer_data[index] = 0;\n",
        "    }\n",
        "  }\n",
        "}\n",
        "'''\n"
      ],
      "metadata": {
        "id": "C34Iv7qFrGyG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.utils.checkpoint as cp\n",
        "from mmcv.cnn import (ConvModule, build_conv_layer, build_norm_layer,\n",
        "                      constant_init, kaiming_init)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Uxdo6WgTz2aQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall mmcv -y\n",
        "#!pip install mmcv-full==1.3.14\n"
      ],
      "metadata": {
        "id": "62ps2vhk1G4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from abc import ABCMeta, abstractmethod\n",
        "\n",
        "import torch.nn as nn\n",
        "from mmcv.runner import load_checkpoint\n",
        "\n",
        "\n",
        "class BaseBackbone(nn.Module, metaclass=ABCMeta):\n",
        "    \"\"\"Base backbone.\n",
        "    This class defines the basic functions of a backbone.\n",
        "    Any backbone that inherits this class should at least\n",
        "    define its own `forward` function.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(BaseBackbone, self).__init__()\n",
        "\n",
        "    def init_weights(self, pretrained=None):\n",
        "        \"\"\"Init backbone weights\n",
        "        Args:\n",
        "            pretrained (str | None): If pretrained is a string, then it\n",
        "                initializes backbone weights by loading the pretrained\n",
        "                checkpoint. If pretrained is None, then it follows default\n",
        "                initializer or customized initializer in subclasses.\n",
        "        \"\"\"\n",
        "        if isinstance(pretrained, str):\n",
        "            logger = logging.getLogger()\n",
        "            load_checkpoint(self, pretrained, strict=False, logger=logger)\n",
        "        elif pretrained is None:\n",
        "            # use default initializer or customized initializer in subclasses\n",
        "            pass\n",
        "        else:\n",
        "            raise TypeError('pretrained must be a str or None.'\n",
        "                            f' But received {type(pretrained)}.')\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward computation\n",
        "        Args:\n",
        "            x (tensor | tuple[tensor]): x could be a Torch.tensor or a tuple of\n",
        "                Torch.tensor, containing input data for forward computation.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def train(self, mode=True):\n",
        "        \"\"\"Set module status before forward computation\n",
        "        Args:\n",
        "            mode (bool): Whether it is train_mode or test_mode\n",
        "        \"\"\"\n",
        "        super(BaseBackbone, self).train(mode)"
      ],
      "metadata": {
        "id": "Inl24gOL8IZj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.utils.checkpoint as cp\n",
        "from mmcv.cnn import (ConvModule, build_conv_layer, build_norm_layer,\n",
        "                      constant_init, kaiming_init)\n",
        "from mmcv.utils.parrots_wrapper import _BatchNorm\n",
        "\n",
        "\n",
        "#from ..utils.involution_cuda import involution"
      ],
      "metadata": {
        "id": "QJlbhd_b6_JJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bottleneck(nn.Module):\n",
        "\n",
        "\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 expansion=4,\n",
        "                 stride=1,\n",
        "                 dilation=1,\n",
        "                 downsample=None,\n",
        "                 style='pytorch',\n",
        "                 with_cp=False,\n",
        "                 conv_cfg=None,\n",
        "                 norm_cfg=dict(type='BN')):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        assert style in ['pytorch', 'caffe']\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.expansion = expansion\n",
        "        assert out_channels % expansion == 0\n",
        "        self.mid_channels = out_channels // expansion\n",
        "        self.stride = stride\n",
        "        self.dilation = dilation\n",
        "        self.style = style\n",
        "        self.with_cp = with_cp\n",
        "        self.conv_cfg = conv_cfg\n",
        "        self.norm_cfg = norm_cfg\n",
        "\n",
        "        if self.style == 'pytorch':\n",
        "            self.conv1_stride = 1\n",
        "            self.conv2_stride = stride\n",
        "        else:\n",
        "            self.conv1_stride = stride\n",
        "            self.conv2_stride = 1\n",
        "\n",
        "        self.norm1_name, norm1 = build_norm_layer(\n",
        "            norm_cfg, self.mid_channels, postfix=1)\n",
        "        self.norm2_name, norm2 = build_norm_layer(\n",
        "            norm_cfg, self.mid_channels, postfix=2)\n",
        "        self.norm3_name, norm3 = build_norm_layer(\n",
        "            norm_cfg, out_channels, postfix=3)\n",
        "\n",
        "        self.conv1 = build_conv_layer(\n",
        "            conv_cfg,\n",
        "            in_channels,\n",
        "            self.mid_channels,\n",
        "            kernel_size=1,\n",
        "            stride=self.conv1_stride,\n",
        "            bias=False)\n",
        "        self.add_module(self.norm1_name, norm1)\n",
        "        self.conv2 = involution(self.mid_channels, 7, self.conv2_stride)\n",
        "\n",
        "        self.add_module(self.norm2_name, norm2)\n",
        "        self.conv3 = build_conv_layer(\n",
        "            conv_cfg,\n",
        "            self.mid_channels,\n",
        "            out_channels,\n",
        "            kernel_size=1,\n",
        "            bias=False)\n",
        "        self.add_module(self.norm3_name, norm3)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    @property\n",
        "    def norm1(self):\n",
        "        return getattr(self, self.norm1_name)\n",
        "\n",
        "    @property\n",
        "    def norm2(self):\n",
        "        return getattr(self, self.norm2_name)\n",
        "\n",
        "    @property\n",
        "    def norm3(self):\n",
        "        return getattr(self, self.norm3_name)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        def _inner_forward(x):\n",
        "            identity = x\n",
        "\n",
        "            out = self.conv1(x)\n",
        "            out = self.norm1(out)\n",
        "            out = self.relu(out)\n",
        "\n",
        "            out = self.conv2(out)\n",
        "            out = self.norm2(out)\n",
        "            out = self.relu(out)\n",
        "\n",
        "            out = self.conv3(out)\n",
        "            out = self.norm3(out)\n",
        "\n",
        "            if self.downsample is not None:\n",
        "                identity = self.downsample(x)\n",
        "\n",
        "            out += identity\n",
        "\n",
        "            return out\n",
        "\n",
        "        if self.with_cp and x.requires_grad:\n",
        "            out = cp.checkpoint(_inner_forward, x)\n",
        "        else:\n",
        "            out = _inner_forward(x)\n",
        "\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "def get_expansion(block, expansion=None):\n",
        "    \"\"\".\n",
        "    \"\"\"\n",
        "    if isinstance(expansion, int):\n",
        "        assert expansion > 0\n",
        "    elif expansion is None:\n",
        "        if hasattr(block, 'expansion'):\n",
        "            expansion = block.expansion\n",
        "        elif issubclass(block, Bottleneck):\n",
        "            expansion = 4\n",
        "        else:\n",
        "            raise TypeError(f'expansion is not specified for {block.__name__}')\n",
        "    else:\n",
        "        raise TypeError('expansion must be an integer or None')\n",
        "\n",
        "    return expansion\n",
        "\n",
        "\n",
        "class ResLayer(nn.Sequential):\n",
        "\n",
        "\n",
        "    def __init__(self,\n",
        "                 block,\n",
        "                 num_blocks,\n",
        "                 in_channels,\n",
        "                 out_channels,\n",
        "                 expansion=None,\n",
        "                 stride=1,\n",
        "                 avg_down=False,\n",
        "                 conv_cfg=None,\n",
        "                 norm_cfg=dict(type='BN'),\n",
        "                 **kwargs):\n",
        "        self.block = block\n",
        "        self.expansion = get_expansion(block, expansion)\n",
        "\n",
        "        downsample = None\n",
        "        if stride != 1 or in_channels != out_channels:\n",
        "            downsample = []\n",
        "            conv_stride = stride\n",
        "            if avg_down and stride != 1:\n",
        "                conv_stride = 1\n",
        "                downsample.append(\n",
        "                    nn.AvgPool2d(\n",
        "                        kernel_size=stride,\n",
        "                        stride=stride,\n",
        "                        ceil_mode=True,\n",
        "                        count_include_pad=False))\n",
        "            downsample.extend([\n",
        "                build_conv_layer(\n",
        "                    conv_cfg,\n",
        "                    in_channels,\n",
        "                    out_channels,\n",
        "                    kernel_size=1,\n",
        "                    stride=conv_stride,\n",
        "                    bias=False),\n",
        "                build_norm_layer(norm_cfg, out_channels)[1]\n",
        "            ])\n",
        "            downsample = nn.Sequential(*downsample)\n",
        "\n",
        "        layers = []\n",
        "        layers.append(\n",
        "            block(\n",
        "                in_channels=in_channels,\n",
        "                out_channels=out_channels,\n",
        "                expansion=self.expansion,\n",
        "                stride=stride,\n",
        "                downsample=downsample,\n",
        "                conv_cfg=conv_cfg,\n",
        "                norm_cfg=norm_cfg,\n",
        "                **kwargs))\n",
        "        in_channels = out_channels\n",
        "        for i in range(1, num_blocks):\n",
        "            layers.append(\n",
        "                block(\n",
        "                    in_channels=in_channels,\n",
        "                    out_channels=out_channels,\n",
        "                    expansion=self.expansion,\n",
        "                    stride=1,\n",
        "                    conv_cfg=conv_cfg,\n",
        "                    norm_cfg=norm_cfg,\n",
        "                    **kwargs))\n",
        "        super(ResLayer, self).__init__(*layers)\n",
        "\n",
        "\n",
        "\n",
        "class RedNet(BaseBackbone):\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    arch_settings = {\n",
        "        26: (Bottleneck, (1, 2, 4, 1)),\n",
        "        38: (Bottleneck, (2, 3, 5, 2)),\n",
        "        50: (Bottleneck, (3, 4, 6, 3)),\n",
        "        101: (Bottleneck, (3, 4, 23, 3)),\n",
        "        152: (Bottleneck, (3, 8, 36, 3))\n",
        "    }\n",
        "\n",
        "    def __init__(self,\n",
        "                 depth,\n",
        "                 in_channels=3,\n",
        "                 stem_channels=64,\n",
        "                 base_channels=64,\n",
        "                 expansion=None,\n",
        "                 num_stages=4,\n",
        "                 strides=(1, 2, 2, 2),\n",
        "                 dilations=(1, 1, 1, 1),\n",
        "                 out_indices=(3, ),\n",
        "                 style='pytorch',\n",
        "                 avg_down=False,\n",
        "                 frozen_stages=-1,\n",
        "                 conv_cfg=None,\n",
        "                 norm_cfg=dict(type='BN', requires_grad=True),\n",
        "                 norm_eval=False,\n",
        "                 with_cp=False,\n",
        "                 zero_init_residual=True):\n",
        "        super(RedNet, self).__init__()\n",
        "        if depth not in self.arch_settings:\n",
        "            raise KeyError(f'invalid depth {depth} for resnet')\n",
        "        self.depth = depth\n",
        "        self.stem_channels = stem_channels\n",
        "        self.base_channels = base_channels\n",
        "        self.num_stages = num_stages\n",
        "        assert num_stages >= 1 and num_stages <= 4\n",
        "        self.strides = strides\n",
        "        self.dilations = dilations\n",
        "        assert len(strides) == len(dilations) == num_stages\n",
        "        self.out_indices = out_indices\n",
        "        assert max(out_indices) < num_stages\n",
        "        self.style = style\n",
        "        self.avg_down = avg_down\n",
        "        self.frozen_stages = frozen_stages\n",
        "        self.conv_cfg = conv_cfg\n",
        "        self.norm_cfg = norm_cfg\n",
        "        self.with_cp = with_cp\n",
        "        self.norm_eval = norm_eval\n",
        "        self.zero_init_residual = zero_init_residual\n",
        "        self.block, stage_blocks = self.arch_settings[depth]\n",
        "        self.stage_blocks = stage_blocks[:num_stages]\n",
        "        self.expansion = get_expansion(self.block, expansion)\n",
        "\n",
        "        self._make_stem_layer(in_channels, stem_channels)\n",
        "\n",
        "        self.res_layers = []\n",
        "        _in_channels = stem_channels\n",
        "        _out_channels = base_channels * self.expansion\n",
        "        for i, num_blocks in enumerate(self.stage_blocks):\n",
        "            stride = strides[i]\n",
        "            dilation = dilations[i]\n",
        "            res_layer = self.make_res_layer(\n",
        "                block=self.block,\n",
        "                num_blocks=num_blocks,\n",
        "                in_channels=_in_channels,\n",
        "                out_channels=_out_channels,\n",
        "                expansion=self.expansion,\n",
        "                stride=stride,\n",
        "                dilation=dilation,\n",
        "                style=self.style,\n",
        "                avg_down=self.avg_down,\n",
        "                with_cp=with_cp,\n",
        "                conv_cfg=conv_cfg,\n",
        "                norm_cfg=norm_cfg)\n",
        "            _in_channels = _out_channels\n",
        "            _out_channels *= 2\n",
        "            layer_name = f'layer{i + 1}'\n",
        "            self.add_module(layer_name, res_layer)\n",
        "            self.res_layers.append(layer_name)\n",
        "\n",
        "        self._freeze_stages()\n",
        "\n",
        "        self.feat_dim = res_layer[-1].out_channels\n",
        "\n",
        "    def make_res_layer(self, **kwargs):\n",
        "        return ResLayer(**kwargs)\n",
        "\n",
        "    @property\n",
        "    def norm1(self):\n",
        "        return getattr(self, self.norm1_name)\n",
        "\n",
        "    def _make_stem_layer(self, in_channels, stem_channels):\n",
        "        self.stem = nn.Sequential(\n",
        "            ConvModule(\n",
        "                in_channels,\n",
        "                stem_channels // 2,\n",
        "                kernel_size=3,\n",
        "                stride=2,\n",
        "                padding=1,\n",
        "                conv_cfg=self.conv_cfg,\n",
        "                norm_cfg=self.norm_cfg,\n",
        "                inplace=True),\n",
        "            involution(stem_channels // 2, 3, 1),\n",
        "            nn.BatchNorm2d(stem_channels // 2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            ConvModule(\n",
        "                stem_channels // 2,\n",
        "                stem_channels,\n",
        "                kernel_size=3,\n",
        "                stride=1,\n",
        "                padding=1,\n",
        "                conv_cfg=self.conv_cfg,\n",
        "                norm_cfg=self.norm_cfg,\n",
        "                inplace=True))\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "    def _freeze_stages(self):\n",
        "        if self.frozen_stages >= 0:\n",
        "            self.stem.eval()\n",
        "            for param in self.stem.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "        for i in range(1, self.frozen_stages + 1):\n",
        "            m = getattr(self, f'layer{i}')\n",
        "            m.eval()\n",
        "            for param in m.parameters():\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def init_weights(self, pretrained=None):\n",
        "        super(RedNet, self).init_weights(pretrained)\n",
        "        if pretrained is None:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, nn.Conv2d):\n",
        "                    kaiming_init(m)\n",
        "                elif isinstance(m, (_BatchNorm, nn.GroupNorm)):\n",
        "                    constant_init(m, 1)\n",
        "\n",
        "            if self.zero_init_residual:\n",
        "                for m in self.modules():\n",
        "                    if isinstance(m, Bottleneck):\n",
        "                        constant_init(m.norm3, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.maxpool(x)\n",
        "        outs = []\n",
        "        for i, layer_name in enumerate(self.res_layers):\n",
        "            res_layer = getattr(self, layer_name)\n",
        "            x = res_layer(x)\n",
        "            if i in self.out_indices:\n",
        "                outs.append(x)\n",
        "        if len(outs) == 1:\n",
        "            return outs[0]\n",
        "        else:\n",
        "            return tuple(outs)\n",
        "\n",
        "    def train(self, mode=True):\n",
        "        super(RedNet, self).train(mode)\n",
        "        self._freeze_stages()\n",
        "        if mode and self.norm_eval:\n",
        "            for m in self.modules():\n",
        "                # trick: eval have effect on BatchNorm only\n",
        "                if isinstance(m, _BatchNorm):\n",
        "                    m.eval()"
      ],
      "metadata": {
        "id": "AQx-3V00qcOg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model settings\n",
        "model = dict(\n",
        "    type='ImageClassifier',\n",
        "    backbone=dict(\n",
        "        type='RedNet',\n",
        "        depth=26,\n",
        "        num_stages=4,\n",
        "        out_indices=(3, ),\n",
        "        style='pytorch'),\n",
        "    neck=dict(type='GlobalAveragePooling'),\n",
        "    head=dict(\n",
        "        type='LinearClsHead',\n",
        "        num_classes=10,\n",
        "        in_channels=2048,\n",
        "        loss=dict(\n",
        "            type='LabelSmoothLoss',\n",
        "            loss_weight=1.0,\n",
        "            label_smooth_val=0.1,\n",
        "            num_classes=10),\n",
        "        topk=(1, 5),\n",
        "    ))"
      ],
      "metadata": {
        "id": "RbjbUXb8c-Pe"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchsummary import summary\n",
        "\n",
        "# create an instance of your model\n",
        "model = RedNet(depth=26)\n",
        "\n",
        "# print the summary of your model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "summary(model, (3,32,32))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jt-VzWmYc_5N",
        "outputId": "9bc72c2e-3cac-4033-8108-78dd790440de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 16, 16]             864\n",
            "       BatchNorm2d-2           [-1, 32, 16, 16]              64\n",
            "              ReLU-3           [-1, 32, 16, 16]               0\n",
            "        ConvModule-4           [-1, 32, 16, 16]               0\n",
            "            Conv2d-5            [-1, 8, 16, 16]             256\n",
            "       BatchNorm2d-6            [-1, 8, 16, 16]              16\n",
            "              ReLU-7            [-1, 8, 16, 16]               0\n",
            "        ConvModule-8            [-1, 8, 16, 16]               0\n",
            "            Conv2d-9           [-1, 18, 16, 16]             162\n",
            "       ConvModule-10           [-1, 18, 16, 16]               0\n",
            "           Unfold-11             [-1, 288, 256]               0\n",
            "       involution-12           [-1, 32, 16, 16]               0\n",
            "      BatchNorm2d-13           [-1, 32, 16, 16]              64\n",
            "             ReLU-14           [-1, 32, 16, 16]               0\n",
            "           Conv2d-15           [-1, 64, 16, 16]          18,432\n",
            "      BatchNorm2d-16           [-1, 64, 16, 16]             128\n",
            "             ReLU-17           [-1, 64, 16, 16]               0\n",
            "       ConvModule-18           [-1, 64, 16, 16]               0\n",
            "        MaxPool2d-19             [-1, 64, 8, 8]               0\n",
            "           Conv2d-20             [-1, 64, 8, 8]           4,096\n",
            "      BatchNorm2d-21             [-1, 64, 8, 8]             128\n",
            "             ReLU-22             [-1, 64, 8, 8]               0\n",
            "           Conv2d-23             [-1, 16, 8, 8]           1,024\n",
            "      BatchNorm2d-24             [-1, 16, 8, 8]              32\n",
            "             ReLU-25             [-1, 16, 8, 8]               0\n",
            "       ConvModule-26             [-1, 16, 8, 8]               0\n",
            "           Conv2d-27            [-1, 196, 8, 8]           3,332\n",
            "       ConvModule-28            [-1, 196, 8, 8]               0\n",
            "           Unfold-29             [-1, 3136, 64]               0\n",
            "       involution-30             [-1, 64, 8, 8]               0\n",
            "      BatchNorm2d-31             [-1, 64, 8, 8]             128\n",
            "             ReLU-32             [-1, 64, 8, 8]               0\n",
            "           Conv2d-33            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-34            [-1, 256, 8, 8]             512\n",
            "           Conv2d-35            [-1, 256, 8, 8]          16,384\n",
            "      BatchNorm2d-36            [-1, 256, 8, 8]             512\n",
            "             ReLU-37            [-1, 256, 8, 8]               0\n",
            "       Bottleneck-38            [-1, 256, 8, 8]               0\n",
            "           Conv2d-39            [-1, 128, 8, 8]          32,768\n",
            "      BatchNorm2d-40            [-1, 128, 8, 8]             256\n",
            "             ReLU-41            [-1, 128, 8, 8]               0\n",
            "        AvgPool2d-42            [-1, 128, 4, 4]               0\n",
            "           Conv2d-43             [-1, 32, 4, 4]           4,096\n",
            "      BatchNorm2d-44             [-1, 32, 4, 4]              64\n",
            "             ReLU-45             [-1, 32, 4, 4]               0\n",
            "       ConvModule-46             [-1, 32, 4, 4]               0\n",
            "           Conv2d-47            [-1, 392, 4, 4]          12,936\n",
            "       ConvModule-48            [-1, 392, 4, 4]               0\n",
            "           Unfold-49             [-1, 6272, 16]               0\n",
            "       involution-50            [-1, 128, 4, 4]               0\n",
            "      BatchNorm2d-51            [-1, 128, 4, 4]             256\n",
            "             ReLU-52            [-1, 128, 4, 4]               0\n",
            "           Conv2d-53            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-54            [-1, 512, 4, 4]           1,024\n",
            "           Conv2d-55            [-1, 512, 4, 4]         131,072\n",
            "      BatchNorm2d-56            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-57            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-58            [-1, 512, 4, 4]               0\n",
            "           Conv2d-59            [-1, 128, 4, 4]          65,536\n",
            "      BatchNorm2d-60            [-1, 128, 4, 4]             256\n",
            "             ReLU-61            [-1, 128, 4, 4]               0\n",
            "           Conv2d-62             [-1, 32, 4, 4]           4,096\n",
            "      BatchNorm2d-63             [-1, 32, 4, 4]              64\n",
            "             ReLU-64             [-1, 32, 4, 4]               0\n",
            "       ConvModule-65             [-1, 32, 4, 4]               0\n",
            "           Conv2d-66            [-1, 392, 4, 4]          12,936\n",
            "       ConvModule-67            [-1, 392, 4, 4]               0\n",
            "           Unfold-68             [-1, 6272, 16]               0\n",
            "       involution-69            [-1, 128, 4, 4]               0\n",
            "      BatchNorm2d-70            [-1, 128, 4, 4]             256\n",
            "             ReLU-71            [-1, 128, 4, 4]               0\n",
            "           Conv2d-72            [-1, 512, 4, 4]          65,536\n",
            "      BatchNorm2d-73            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-74            [-1, 512, 4, 4]               0\n",
            "       Bottleneck-75            [-1, 512, 4, 4]               0\n",
            "           Conv2d-76            [-1, 256, 4, 4]         131,072\n",
            "      BatchNorm2d-77            [-1, 256, 4, 4]             512\n",
            "             ReLU-78            [-1, 256, 4, 4]               0\n",
            "        AvgPool2d-79            [-1, 256, 2, 2]               0\n",
            "           Conv2d-80             [-1, 64, 2, 2]          16,384\n",
            "      BatchNorm2d-81             [-1, 64, 2, 2]             128\n",
            "             ReLU-82             [-1, 64, 2, 2]               0\n",
            "       ConvModule-83             [-1, 64, 2, 2]               0\n",
            "           Conv2d-84            [-1, 784, 2, 2]          50,960\n",
            "       ConvModule-85            [-1, 784, 2, 2]               0\n",
            "           Unfold-86             [-1, 12544, 4]               0\n",
            "       involution-87            [-1, 256, 2, 2]               0\n",
            "      BatchNorm2d-88            [-1, 256, 2, 2]             512\n",
            "             ReLU-89            [-1, 256, 2, 2]               0\n",
            "           Conv2d-90           [-1, 1024, 2, 2]         262,144\n",
            "      BatchNorm2d-91           [-1, 1024, 2, 2]           2,048\n",
            "           Conv2d-92           [-1, 1024, 2, 2]         524,288\n",
            "      BatchNorm2d-93           [-1, 1024, 2, 2]           2,048\n",
            "             ReLU-94           [-1, 1024, 2, 2]               0\n",
            "       Bottleneck-95           [-1, 1024, 2, 2]               0\n",
            "           Conv2d-96            [-1, 256, 2, 2]         262,144\n",
            "      BatchNorm2d-97            [-1, 256, 2, 2]             512\n",
            "             ReLU-98            [-1, 256, 2, 2]               0\n",
            "           Conv2d-99             [-1, 64, 2, 2]          16,384\n",
            "     BatchNorm2d-100             [-1, 64, 2, 2]             128\n",
            "            ReLU-101             [-1, 64, 2, 2]               0\n",
            "      ConvModule-102             [-1, 64, 2, 2]               0\n",
            "          Conv2d-103            [-1, 784, 2, 2]          50,960\n",
            "      ConvModule-104            [-1, 784, 2, 2]               0\n",
            "          Unfold-105             [-1, 12544, 4]               0\n",
            "      involution-106            [-1, 256, 2, 2]               0\n",
            "     BatchNorm2d-107            [-1, 256, 2, 2]             512\n",
            "            ReLU-108            [-1, 256, 2, 2]               0\n",
            "          Conv2d-109           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-110           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-111           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-112           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-113            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-114            [-1, 256, 2, 2]             512\n",
            "            ReLU-115            [-1, 256, 2, 2]               0\n",
            "          Conv2d-116             [-1, 64, 2, 2]          16,384\n",
            "     BatchNorm2d-117             [-1, 64, 2, 2]             128\n",
            "            ReLU-118             [-1, 64, 2, 2]               0\n",
            "      ConvModule-119             [-1, 64, 2, 2]               0\n",
            "          Conv2d-120            [-1, 784, 2, 2]          50,960\n",
            "      ConvModule-121            [-1, 784, 2, 2]               0\n",
            "          Unfold-122             [-1, 12544, 4]               0\n",
            "      involution-123            [-1, 256, 2, 2]               0\n",
            "     BatchNorm2d-124            [-1, 256, 2, 2]             512\n",
            "            ReLU-125            [-1, 256, 2, 2]               0\n",
            "          Conv2d-126           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-127           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-128           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-129           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-130            [-1, 256, 2, 2]         262,144\n",
            "     BatchNorm2d-131            [-1, 256, 2, 2]             512\n",
            "            ReLU-132            [-1, 256, 2, 2]               0\n",
            "          Conv2d-133             [-1, 64, 2, 2]          16,384\n",
            "     BatchNorm2d-134             [-1, 64, 2, 2]             128\n",
            "            ReLU-135             [-1, 64, 2, 2]               0\n",
            "      ConvModule-136             [-1, 64, 2, 2]               0\n",
            "          Conv2d-137            [-1, 784, 2, 2]          50,960\n",
            "      ConvModule-138            [-1, 784, 2, 2]               0\n",
            "          Unfold-139             [-1, 12544, 4]               0\n",
            "      involution-140            [-1, 256, 2, 2]               0\n",
            "     BatchNorm2d-141            [-1, 256, 2, 2]             512\n",
            "            ReLU-142            [-1, 256, 2, 2]               0\n",
            "          Conv2d-143           [-1, 1024, 2, 2]         262,144\n",
            "     BatchNorm2d-144           [-1, 1024, 2, 2]           2,048\n",
            "            ReLU-145           [-1, 1024, 2, 2]               0\n",
            "      Bottleneck-146           [-1, 1024, 2, 2]               0\n",
            "          Conv2d-147            [-1, 512, 2, 2]         524,288\n",
            "     BatchNorm2d-148            [-1, 512, 2, 2]           1,024\n",
            "            ReLU-149            [-1, 512, 2, 2]               0\n",
            "       AvgPool2d-150            [-1, 512, 1, 1]               0\n",
            "          Conv2d-151            [-1, 128, 1, 1]          65,536\n",
            "     BatchNorm2d-152            [-1, 128, 1, 1]             256\n",
            "            ReLU-153            [-1, 128, 1, 1]               0\n",
            "      ConvModule-154            [-1, 128, 1, 1]               0\n",
            "          Conv2d-155           [-1, 1568, 1, 1]         202,272\n",
            "      ConvModule-156           [-1, 1568, 1, 1]               0\n",
            "          Unfold-157             [-1, 25088, 1]               0\n",
            "      involution-158            [-1, 512, 1, 1]               0\n",
            "     BatchNorm2d-159            [-1, 512, 1, 1]           1,024\n",
            "            ReLU-160            [-1, 512, 1, 1]               0\n",
            "          Conv2d-161           [-1, 2048, 1, 1]       1,048,576\n",
            "     BatchNorm2d-162           [-1, 2048, 1, 1]           4,096\n",
            "          Conv2d-163           [-1, 2048, 1, 1]       2,097,152\n",
            "     BatchNorm2d-164           [-1, 2048, 1, 1]           4,096\n",
            "            ReLU-165           [-1, 2048, 1, 1]               0\n",
            "      Bottleneck-166           [-1, 2048, 1, 1]               0\n",
            "================================================================\n",
            "Total params: 7,184,166\n",
            "Trainable params: 7,184,166\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 10.04\n",
            "Params size (MB): 27.41\n",
            "Estimated Total Size (MB): 37.45\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transforms)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Tu1ueJx7fYIw",
        "outputId": "0f4d184a-9f66-4946-9381-d06cc924cb85"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:13<00:00, 13099201.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data as data\n",
        "\n",
        "trainloader = data.DataLoader(trainset, batch_size=128, shuffle=False, num_workers=2)\n",
        "testloader = data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "id": "gpt68mXIfaHL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "Ff9rndyE0kAf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class RedNetClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(RedNetClassifier, self).__init__()\n",
        "        self.backbone = RedNet(depth=26, num_stages=4, out_indices=(3,), style='pytorch')\n",
        "        self.head = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d((1, 1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2048, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.head(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the classifier\n",
        "model = RedNetClassifier(num_classes=10)\n",
        "\n",
        "# Pass the model's parameters to the optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n"
      ],
      "metadata": {
        "id": "r0iDIFTOLvg9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the optimizer and learning rate scheduler\n",
        "#optimizer = optim.SGD(model.parameters(), lr=0.8, momentum=0.9, weight_decay=0.0001, nesterov=True)\n",
        "#lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=130, eta_min=0)"
      ],
      "metadata": {
        "id": "qz4jiUlVMoVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)\n",
        "data = data.to(device)\n",
        "new_data = torch.zeros_like(data, device=device, dtype=torch.float32)\n",
        "new_data.copy_(data)\n",
        "output = model(new_data)\n",
        "\n"
      ],
      "metadata": {
        "id": "-IfkEt4lg6Ql",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "outputId": "0ac66e08-39a8-466a-f651-6836a503e46c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-0fb17d7bafd7>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnew_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torch.utils.data' has no attribute 'to'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "04XY-CK94-cF"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "num_epochs = 200\n",
        "lr_schedule = [80, 120, 160]\n",
        "\n",
        "def schedule(epoch_idx):\n",
        "    if (epoch_idx + 1) < lr_schedule[0]:\n",
        "        return 0.1\n",
        "    elif (epoch_idx + 1) > lr_schedule[0] and (epoch_idx + 1) < lr_schedule[1]:\n",
        "    # Code to execute when epoch_idx is between lr_schedule[0] and lr_schedule[1]\n",
        "        return 0.01 # lr_decay_ratio = 0.2\n",
        "    elif (epoch_idx + 1)>=lr_schedule[1] and (epoch_idx + 1) < lr_schedule[2]:\n",
        "        return 0.001\n",
        "    return 0.0008\n",
        "# Define your optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9,nesterov=True)\n",
        "\n",
        "# Define your learning rate scheduler\n",
        "lr_scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: schedule(epoch))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KXZW85pXI_Us"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_decay = 0.0001"
      ],
      "metadata": {
        "id": "u1pqADWKJpLM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "# create a summary writer for TensorBoard\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "num_epochs = 1\n",
        "rednet_targets=[]\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    for batch_idx, (data, target) in enumerate(trainloader):\n",
        "        data = data.to(device)  # move the data to the GPU\n",
        "        target = target.to(device)  # move the data to the GPU\n",
        "        rednet_targets.append(target)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # compute training accuracy\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        train_total += target.size(0)\n",
        "        train_correct += (predicted == target).sum().item()\n",
        "\n",
        "    train_acc = 100 * train_correct / train_total\n",
        "    lr_scheduler.step()\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        for data, target in testloader:\n",
        "            data = data.to(device)  # move the data to the GPU\n",
        "            target = target.to(device)  # move the data to the GPU\n",
        "            output = model(data)\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "        acc = 100 * correct / total\n",
        "    rednet_targets = torch.cat(rednet_targets, dim=0)\n",
        "    print(rednet_targets.shape)\n",
        "    # Save the targets to a .pt file\n",
        "    torch.save(rednet_targets, 'rednet_targets.pt')\n",
        "    print('Epoch: {} - Loss: {:.4f} - Train accuracy: {:.2f}% - Test accuracy: {:.2f}%'.format(epoch+1, loss.item(), train_acc, acc))\n",
        "     #lr_scheduler.step()\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "total_time = end_time - start_time\n",
        "\n",
        "print(f'Total training time: {total_time:.2f} seconds')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uvyRIu7dMEl_",
        "outputId": "ba54531c-efd9-4cce-d7e8-959f4db26923"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50000])\n",
            "Epoch: 1 - Loss: 1.6150 - Train accuracy: 27.88% - Test accuracy: 41.67%\n",
            "Total training time: 18.32 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RednetTest = torch.save(model.state_dict(), 'Rednettest.T7')"
      ],
      "metadata": {
        "id": "kgK65acL8j3w"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rednet_targets = torch.load('/content/rednet_targets.pt')\n",
        "print(rednet_targets)\n",
        "print(rednet_targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "OYmSDCtjTBSs",
        "outputId": "a41e75a2-2334-4ce7-943b-e71a85763923"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6, 9, 9,  ..., 9, 1, 1], device='cuda:0')\n",
            "torch.Size([50000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rednet_targets = torch.load('/content/drive/MyDrive/RednetExp29july/concatenated_subset1.pt')\n",
        "print(rednet_targets)\n",
        "print(rednet_targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bGyyTw8cqPBc",
        "outputId": "08234735-1e90-4355-cfcc-afa74f8396c8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[  0.4628, -18.5866,  -2.4622,  ...,   8.7815,  -5.7277, -15.7938],\n",
            "        [  0.4969, -11.9467,   4.1564,  ...,   4.3835,   7.6666,   7.2141],\n",
            "        [  6.2863, -12.6247,   3.4577,  ...,   1.8666,   5.4522,  -0.9015],\n",
            "        ...,\n",
            "        [ 10.1681,   1.9288,  -0.1346,  ...,  -7.9062,   9.7158,   0.6753],\n",
            "        [  1.9233, -16.4646,   2.9002,  ...,   1.5539,  -3.6887,  -7.6992],\n",
            "        [  9.5798, -10.6653,  -8.2000,  ...,   4.9272,   8.4362,   8.0167]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "torch.Size([49998, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load the tensor from the specified file\n",
        "rednet_targets = torch.load('/content/drive/MyDrive/RednetExp29july/concatenated_subset11.pt')\n",
        "\n",
        "# Print the loaded tensor and its shape\n",
        "#print(rednet_targets)\n",
        "#print(rednet_targets.shape)\n",
        "\n",
        "# Apply the argmax function along a specified dimension (e.g., dim=1)\n",
        "rednet_targets= torch.argmax(rednet_targets, dim=1)\n",
        "print(rednet_targets.shape)\n",
        "print(rednet_targets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bSqU4XT8rAZo",
        "outputId": "f2d7ceee-c0c4-4c7a-de41-16c03929fd77"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([49998])\n",
            "tensor([6, 9, 8,  ..., 8, 6, 9], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load the tensor from the specified file\n",
        "Deit_targets = torch.load('/content/saved_targets123.pt')\n",
        "print(Deit_targets)\n",
        "print(Deit_targets .shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1tByFcgUrP1s",
        "outputId": "b4a7580b-a667-445b-fc5b-84cf528a7464"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6, 9, 9,  ..., 9, 1, 1], device='cuda:0')\n",
            "torch.Size([50000])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Deit_targets  = Deit_targets [:49998]\n",
        "\n",
        "print(Deit_targets )\n",
        "print(Deit_targets .shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LRbZZ41R18VM",
        "outputId": "f3fdd56a-ec40-4529-bdb9-3070569162c5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6, 9, 9,  ..., 2, 6, 9], device='cuda:0')\n",
            "torch.Size([49998])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rednet_targets11 = torch.load('/content/rednet_targets.pt')\n",
        "print(rednet_targets11)\n",
        "print(rednet_targets11)\n",
        "rednet_targets11  = rednet_targets11  [:49998]\n",
        "\n",
        "print(rednet_targets11 )\n",
        "print(rednet_targets11 .shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FRkY2Fw65Q3a",
        "outputId": "36139d8f-9712-4523-f3d1-665e7893fddf"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([6, 9, 9,  ..., 9, 1, 1], device='cuda:0')\n",
            "tensor([6, 9, 9,  ..., 9, 1, 1], device='cuda:0')\n",
            "tensor([6, 9, 9,  ..., 2, 6, 9], device='cuda:0')\n",
            "torch.Size([49998])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.eq(rednet_targets11 , rednet_targets).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KYAipVCQ2Xb3",
        "outputId": "1b66b3c3-af07-489b-da0c-1bc6bae2910b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(18923, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# define the file path to save the model\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Colab/model4.pt'\n",
        "\n",
        "# save the entire model\n",
        "torch.save(model.state_dict, file_path)\n",
        "\n",
        "# save the entire model\n",
        "torch.save(model, file_path)\n"
      ],
      "metadata": {
        "id": "YHSIWh6IrJLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generating Training logits from pretrained models**"
      ],
      "metadata": {
        "id": "AqCtbLcM9he-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import Subset\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data.dataloader import default_collate\n",
        "\n",
        "#dataset Transforms\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "    #transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "])\n",
        "\n",
        "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
        "trainloader = data.DataLoader(trainset, batch_size=128, shuffle=False, num_workers=2)\n",
        "\n",
        "#dividing Dataset into five subsets\n",
        "\n",
        "num_samples = len(trainset) // 6\n",
        "print(num_samples)\n",
        "\n",
        "subset_datasets = []\n",
        "subset_loaders = []\n",
        "\n",
        "for i in range(6):\n",
        "    # Calculate the starting and ending indices for the current subset\n",
        "    start_idx = i * num_samples\n",
        "    end_idx = (i + 1) * num_samples\n",
        "\n",
        "    # Create a subset of the training dataset using the current indices\n",
        "    subset_indices = torch.arange(start_idx, end_idx)\n",
        "    subset_dataset = Subset(trainset, subset_indices)\n",
        "    subset_datasets.append(subset_dataset)\n",
        "\n",
        "    # Create a DataLoader for the current subset\n",
        "    subset_loader = DataLoader(subset_dataset, batch_size=128, shuffle=False)\n",
        "    subset_loaders.append(subset_loader)\n",
        "\n",
        "# Example usage: access the subsets and their respective loaders\n",
        "\n",
        "subset1 = subset_datasets[0]\n",
        "subset_loader1 = subset_loaders[0]\n",
        "#print(subset1)\n",
        "\n",
        "\n",
        "subset2 = subset_datasets[1]\n",
        "subset_loader2 = subset_loaders[1]\n",
        "#print(subset2)\n",
        "\n",
        "subset3 = subset_datasets[2]\n",
        "subset_loader3 = subset_loaders[2]\n",
        "#print(subset3)\n",
        "\n",
        "subset4 = subset_datasets[3]\n",
        "subset_loader4 = subset_loaders[3]\n",
        "#print(subset4)\n",
        "\n",
        "\n",
        "subset5 = subset_datasets[4]\n",
        "subset_loader5 = subset_loaders[4]\n",
        "\n",
        "subset6 = subset_datasets[5]\n",
        "subset_loader6 = subset_loaders[5]\n",
        "\n",
        "#print(subset5)\n",
        "\n",
        "#trainloader1 = DataLoader(subset1, batch_size=64, shuffle=False,\n",
        "                    #collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))\n",
        "trainloader1 = DataLoader(subset1, batch_size=128, shuffle=False,\n",
        "                    collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))\n",
        "#trainloader3 = DataLoader(subset3, batch_size=128, shuffle=False,\n",
        "                    #collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))\n",
        "#trainloader4 = DataLoader(subset4, batch_size=128, shuffle=False,\n",
        "                    #collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))\n",
        "#trainloader5 = DataLoader(subset5, batch_size=128, shuffle=False,\n",
        "                    #collate_fn=lambda x: tuple(x_.to(device) for x_ in default_collate(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHlD2ArH99rk",
        "outputId": "ec56ec32-96dd-4e08-d8f9-b44108f5c5b5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "8333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Clear GPU memory\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "GjY6OtVy-IrS"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model on CPU\n",
        "model1 = RedNetClassifier(num_classes=10)\n",
        "model1.load_state_dict(torch.load('/content/Rednettest.T7', map_location='cpu'))\n",
        "\n",
        "# Move the model to GPU\n",
        "model1.to('cuda')\n",
        "import torch\n",
        "\n",
        "# Check available GPU memory\n",
        "print(f\"Currently allocated GPU memory: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
        "print(f\"Max allocated GPU memory: {torch.cuda.max_memory_allocated() / 1024**2:.2f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pwZ_iWFX-MS8",
        "outputId": "489b0422-2d2e-4080-b2e3-28e0041ce09e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently allocated GPU memory: 129.53 MB\n",
            "Max allocated GPU memory: 725.53 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Assuming you have defined your model and loaded the trained weights\n",
        "#model1 = RedNetClassifier(num_classes=10)\n",
        "\n",
        "#model1.load_state_dict(torch.load('/content/drive/MyDrive/RednetExp29july/Rednet0.T7'))\n",
        "\n",
        "# Assuming you're using GPU, move the model to GPU\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "#print(device)\n",
        "#model1.to(device)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model1.eval()\n",
        "\n",
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Variables to track metrics\n",
        "total_loss = 0.0\n",
        "correct_predictions = 0\n",
        "total_predictions = 0\n",
        "soft_outputs=[]\n",
        "\n",
        "rednet_target1=[]\n",
        "# Iterate over the test dataset\n",
        "for images, target in subset_loader6:\n",
        "    images = images.to(device)\n",
        "    target = target.to(device)\n",
        "    #print(images.is_cuda)\n",
        "    # Forward pass\n",
        "    outputs = model1(images)\n",
        "    soft_outputs.append(outputs)\n",
        "    rednet_target1.append(target)\n",
        "\n",
        "    # Calculate loss\n",
        "    loss = criterion(outputs, target)\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    # Get predicted labels\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total_predictions += target.size(0)\n",
        "    correct_predictions += (predicted == target).sum().item()\n",
        "\n",
        "# Calculate average loss and accuracy\n",
        "\n",
        "print(type(soft_outputs))\n",
        "rednet_target1 = torch.cat(rednet_target1, dim=0)\n",
        "print(rednet_target1.shape)\n",
        "    # Save the targets to a .pt file\n",
        "torch.save(rednet_target1, 'rednet_targetloader5.pt')\n",
        "average_loss = total_loss / len(trainloader1)\n",
        "accuracy = correct_predictions / total_predictions\n",
        "\n",
        "# Save softmax outputs to a file\n",
        "if len(soft_outputs) > 0:\n",
        "    soft_outputs = torch.cat(soft_outputs, dim=0)\n",
        "    torch.save(soft_outputs, 'rednetsubsetloader5.pt')\n",
        "else:\n",
        "    print(\"No softmax outputs to save.\")\n",
        "\n",
        "\n",
        "print(\"Train Loss: {:.4f}\".format(average_loss))\n",
        "print(\"Train Accuracy: {:.2%}\".format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nemq4N51-0pO",
        "outputId": "d38f3f3c-a872-4736-e2ae-631f4b4d507f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "torch.Size([8333])\n",
            "Train Loss: 176.4078\n",
            "Train Accuracy: 17.29%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load the tensor from the specified file\n",
        "rednet_target1 = torch.load('/content/rednet_targetloader.pt')\n",
        "print(rednet_target1.shape)\n",
        "rednet_target2 = torch.load('/content/rednet_targetloader1.pt')\n",
        "print(rednet_target2.shape)\n",
        "rednet_target3 = torch.load('/content/rednet_targetloader2.pt')\n",
        "print(rednet_target3.shape)\n",
        "rednet_target4 = torch.load('/content/rednet_targetloader3.pt')\n",
        "print(rednet_target4.shape)\n",
        "rednet_target5 = torch.load('/content/rednet_targetloader4.pt')\n",
        "print(rednet_target5.shape)\n",
        "rednet_target6 = torch.load('/content/rednet_targetloader5.pt')\n",
        "print(rednet_target6.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngAYWMHPOuI7",
        "outputId": "f4187f97-b559-4322-a02e-37b1b552679a"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8333])\n",
            "torch.Size([8333])\n",
            "torch.Size([8333])\n",
            "torch.Size([8333])\n",
            "torch.Size([8333])\n",
            "torch.Size([8333])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Stack the tensors along the first dimension\n",
        "concatenated_targets = torch.cat((rednet_target1, rednet_target2, rednet_target3, rednet_target4, rednet_target5, rednet_target6), dim=0)\n",
        "\n",
        "print(concatenated_targets.shape)  # This will show the shape of the concatenated tensor\n",
        "print(concatenated_targets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxeoeol2PoS3",
        "outputId": "cba913bd-92fe-4262-ae57-16931bee73eb"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([49998])\n",
            "tensor([6, 9, 9,  ..., 2, 6, 9], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply argmax along dimension 1\n",
        "concatenated_targets = concatenated_targets.argmax(dim=1)\n",
        "print(concatenated_targets.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxcoTQL7QrkY",
        "outputId": "0fbb3242-3126-4f6d-957a-77dcdb5083ba"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([49998])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rednet_targets = torch.load('/content/rednet_targets.pt')\n",
        "print(rednet_targets.shape)\n",
        "import torch\n",
        "\n",
        "\n",
        "# Retain indices up to 49998\n",
        "rednet_targets = rednet_targets[:49998]\n",
        "\n",
        "print(rednet_targets.shape)  # This will show the shape of the retained indices tensor\n",
        "print(rednet_targets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XcWAiEnP4fZ",
        "outputId": "4a7db742-5ed1-48e8-e9a5-44d8fbbc67a4"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50000])\n",
            "torch.Size([49998])\n",
            "tensor([6, 9, 9,  ..., 2, 6, 9], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.eq(rednet_targets , concatenated_targets).sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azIi49L6RA5o",
        "outputId": "d8ff7966-d6ba-46ab-9b12-97838bdaf89e"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8830, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matches = torch.eq(concatenated_targets, rednet_targets)\n",
        "total_matches = matches.sum()\n",
        "\n",
        "print(total_matches)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxht1KE8R8do",
        "outputId": "16f0329c-4e30-42a9-df5e-d3b1cc83d68c"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(8830, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rednet_targets = torch.load('/content/saved_targets123.pt')\n",
        "print(rednet_targets.shape)\n",
        "print(rednet_targets)\n",
        "import torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQDweyylWSPm",
        "outputId": "d3bb5c8d-fbe2-4921-9546-94ba7c9fe784"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([50000])\n",
            "tensor([6, 9, 9,  ..., 9, 1, 1], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Retain indices up to 49998\n",
        "rednet_targets = rednet_targets[:49998]\n",
        "\n",
        "print(rednet_targets.shape)  # This will show the shape of the retained indices tensor\n",
        "print(rednet_targets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOvlSkO9Wvys",
        "outputId": "094ed950-5967-4f7a-c13e-93498c889ff1"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([49998])\n",
            "tensor([6, 9, 9,  ..., 2, 6, 9], device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}